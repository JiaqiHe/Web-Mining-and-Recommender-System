\documentclass{assignment}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{pythonhighlight}
\usepackage{array}
\lstset{
numbers=left
}

\coursetitle{Web Mining and Recommender System}
\courselabel{CSE 258}
\exercisesheet{Homework 3}{}
\student{He, Jiaqi}
\university{University of California, San Diego}
\semester{Fall 2017}
\date{November 10, 2017}

\begin{document}

\section{Task (Visit Prediction)}

\begin{problemlist}

\pbitem 
Although we have built a validation set, it only consists of positive samples. For this task we also need examples of user/business pairs that weren't visited. Build such a set by randomly sampling users and businesses until you have 100,000 non-visited user/business pairs. This random sample combined with your 100,000 validation reviews now corresponds to the complete validation set for the visit prediction task. Evaluate the performance (accuracy) of the baseline model on the validation set you have built (1 mark).

\paragraph{Answer:}
\par
First step is to divide 200,000 data into two parts for training and validation.\\
Secondly, in order to generate 100,000 non-visited user/business pairs, we need a user set and a business set containing all recorded users and businesses. Then we randomly pick one user and one business and check whether this pair has ever existed in 200,000 data. If not, we then successfully generate one pair. Keep doing this until we have 100,000 non-visited pairs.\\
Lastly, evaluate the performance (accuracy) of the baseline model on the validation set.\\
The accuracy is 0.648705.\\
Below is the code for this problem.

\inputpython{hw3_1.py}{1}{78}

\newpage

\pbitem 
The existing 'visit prediction' baseline just returns True if the business in question is 'popular,' using
a threshold of the 50th percentile of popularity (totalVisits/2). Assuming that the 'non-visited' test
examples are a random sample of user-visit pairs, is this particular threshold value the best? If not, see
if you can find a better one (and report its performance), or if so, explain why it is the best (1 mark).

\paragraph{Answer:}
\par
By trying different percentiles, we can get accuracy data in Table \ref{table:percentile}.
\begin{table}[!hbp]
\centering
\caption{Accuracy on the Validation Set with Different Percentiles} 
\begin{tabular}{p{2cm}<{\centering}|p{2cm}<{\centering} p{2cm}<{\centering} p{2cm}<{\centering} p{2cm}<{\centering} p{2cm}<{\centering}}
\hline
Percentile & 1/4  & 1/3  &  1/2  &  2/3  &  3/4  \\  
\hline
Accuracy  & 0.596 & 0.618  &  0.648  &   0.652  &   0.639 \\  
\hline
\end{tabular}
\label{table:percentile}
\end{table} 

By checking the table, we can know that setting percentile to be approximately 2/3 would be better. This ratio is vary close to \textbf{golden ratio}: 0.618, and if we try this percentile, we can get a better result: 0.653435. Golden ratio wins.

\newpage


\pbitem
Users may tend to repeatedly visit business of the same type. Build a baseline that returns 'True' if a user has visited a business of the same category before (at least one category in common), or zero otherwise (1 mark).

\paragraph{Answer:}
In this problem, we need to keep track of each user's visiting history to help determine whether he/she has ever visited a business of same category. \\
First, for each user-business pair in the training set, we add the categories of that business into two dictionaries: u2t(user to type) and b2t(business to type). By doing so, we are storing the categories that each user would visit and each business possesses.\\
Second, validate the model. For each user-business pair, we retrive the categories that this user would visit and the categories that this business possess, we check if these two sets have any intersections. If there exists some intersections, then we say this user would visit this business, return 'True'.\\
Hence, the accuracy of this model on the validation set is: 0.650525.\\
Below is the code for this problem:

\inputpython{hw3_3.py}{1}{84}

\newpage

\pbitem
To run our model on the test set, we'll have to use the files 'pairs Visit.txt' to find the userID/businessID pairs about which we have to make predictions. Using that data, run the above model and upload your solution to Kaggle. Tell us your Kaggle user name (1 mark). If you've already uploaded a better solution to Kaggle, that's fine too!

\paragraph{Answer:}
My Kaggle user name is: \textbf{jih417}, as is shown in Fig. \ref{fig:username}.\\

\begin{figure}[htbp]
	\centering
	\includegraphics[height = 2in]{username}
	\caption{Kaggle profile info}
    \label{fig:username}
\end{figure}

If using the model from problem 3, the score is 0.66490 on Kaggle. We can definitely improve this result by building a collaborative filtering model, which will be solved in assignment 1.

Below is the code for this problem.
\inputpython{hw3_4.py}{1}{63}

\newpage



\section{Task (Rating Prediction)}
\pbitem
What is the performance of a trivial predictor
\begin{equation}
rating(user, item) = \alpha
\end{equation}
on the validation set, and what is the value of $\alpha$ (1 mark)?\\

\paragraph{Answer:}
This model predicts each user-item pair to be the average rating. \\
First, we acquire training data and validation data. On the training set, we add up all ratings and calculate the average rating, namely $\alpha$ in the model. \\
For validation, we just predict $\alpha$ ratings and calculate MSE.\\
Hence, $\alpha$ = 4.18703, and the MSE on the validation set is 0.7483437444993984.

Below is the code for this problem.

\inputpython{hw3_5.py}{1}{31}
\newpage

\pbitem
Fit a predictor of the form
\begin{equation}
rating(user, item) \approx \alpha + \beta_{user} -\beta_{item}
\end{equation}
by fitting the mean and the two bias terms as described in the lecture notes. Use a regularization parameter of $\lambda = 1$. Report the MSE on the validation set (1 mark).

\paragraph{Answer:}
This model is more complex than the previous one.\\
The optimization problem of this model is
\begin{equation}
argmin_{\alpha, \beta} \sum_{u,i}(\alpha + \beta_u +\beta_i - R_{u, i})^2 + \lambda[\sum_u \beta_u^2 + \sum_i \beta_i^2]
\end{equation}
If we differentiate this expression, we can acquire the following:
\begin{equation}
\alpha = \frac{\sum_{u,i \in train}(R_{u,i}-(\beta_u + \beta_i))}{N_{train}}
\end{equation}

\begin{equation}
\beta_u = \frac{\sum_{i \in I_u}(R_{u,i}-(\alpha + \beta_i))}{\lambda + \left|{I_u}\right|}
\end{equation}

\begin{equation}
\beta_i = \frac{\sum_{u \in U_i}(R_{u,i}-(\alpha + \beta_u))}{\lambda + \left|{U_i}\right|}
\end{equation}

We need to repeat the updates above until convergence.\\
After the training, we can try our model on the validation set. The MSE on the validation set is: 0.6456944316928961.\\

Below is the code for this problem.

\inputpython{hw3_6.py}{1}{72}

\newpage


\pbitem
Report the user and item IDs that have the largest and smallest values of $\beta$ (1 mark).
\paragraph{Answer:}
By checking $\beta_u$ and $\beta_i$, we can easily find the user and item with the largest and smallest values.\\
The user that has the largest value of $\beta$ is 'U357799541' with $\beta$ = 1.1643513853119356;\\
The user that has the largest value of $\beta$ is 'U417838537' with $\beta$ = -2.8318415410925115;\\
The item that has the largest value of $\beta$ is 'B093985406' with $\beta$ = 1.1719607471576514;\\
The item that has the smallest value of $\beta$ is 'B241777680' with $\beta$ =  -2.2312453963097525.\\

Below is the code for this problem.

\inputpython{hw3_6.py}{76}{113}

\newpage

\pbitem
Find a better value of $\lambda$ using your validation set. Report the value you chose, its MSE, and upload your solution to Kaggle by running it on the test data (1 mark).
\paragraph{Answer:}
By trying different $\lambda$, we can obtain data in Fig. \ref{fig:lambda}.

\begin{figure}[htbp]
	\centering
	\includegraphics[height = 3in]{lambda}
	\caption{Kaggle profile info}
    \label{fig:lambda}
\end{figure}

Hence, it is a good choice to select $\lambda$ = 10. This time the MSE on the validation set is 0.6214475097509096.\\

Below is the code that has already been modified to make predictions on test file.\\

\inputpython{hw3_8.py}{1}{90}


\end{problemlist}
\end{document}
